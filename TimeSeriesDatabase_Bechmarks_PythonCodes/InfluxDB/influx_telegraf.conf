[agent]
  interval = "10s"                # Collect metrics every 10 seconds
  round_interval = true           # Align collection to even intervals (e.g., 10s exactly)
  metric_batch_size = 600000      # Max number of metrics per batch before sending
  metric_buffer_limit = 600000    # Max number of metrics to buffer if output is down
  flush_interval = "5s"           # How often to flush metrics to the output
  flush_jitter = "0s"              # Random time added to flush_interval to avoid spikes (disabled here)
  precision = ""                  # Precision for timestamps (empty = nanoseconds)
  hostname = "msc-burge-influxdb" # Override hostname tag for metrics
  omit_hostname = false           # Whether to omit the hostname tag (false = include)
  debug = true                    # Enable debug logging for troubleshooting

[[outputs.influxdb_v2]]
  urls = ["http://<vm-ip>:8086"]  # InfluxDB 2.x server URL (replace <vm-ip> with actual VM IP)
  token = "your_token"            # Authentication token for InfluxDB
  organization = "University of Koblenz" # InfluxDB organization name
  bucket = "500k_data"            # Target bucket for storing metrics

[[inputs.file]]
  files = ["/etc/telegraf/500k_row_data_part_0001.csv"] # Path to CSV file with input data
  data_format = "csv"           # Input format
  csv_header_row_count = 1      # Number of header rows to skip before data
  csv_column_names = ["timestamp", "value", "category"] # Column names mapping
  csv_timestamp_column = "timestamp"                   # Column containing the timestamp
  csv_column_types = ["timestamp", "float", "string"]   # Column data types
  csv_timestamp_format = "2006-01-02 15:04:05.999Z07"   # Time format for parsing timestamps
  csv_tag_columns = ["category"]                        # Column(s) to be stored as tags
